{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['patch.force_edgecolor'] = True\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../dataset/\"\n",
    "file= filepath +'training_data.csv'\n",
    "\n",
    "training_data = pd.read_csv(file)\n",
    "\n",
    "bag_of_words_bot = 'bot|b0t'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data['screen_name_binary'] = training_data.screen_name.str.contains(bag_of_words_bot, case=False, na=False)\n",
    "training_data['name_binary'] = training_data.name.str.contains(bag_of_words_bot, case=False, na=False)\n",
    "training_data['description_binary'] = training_data.description.str.contains(bag_of_words_bot, case=False, na=False)\n",
    "training_data['status_binary'] = training_data.status.str.contains(bag_of_words_bot, case=False, na=False)\n",
    "training_data['listed_count_binary'] = (training_data.listed_count>20000)==False\n",
    "\n",
    "features = ['screen_name_binary', 'name_binary', 'description_binary', 'status_binary', 'verified', 'followers_count', 'friends_count', 'statuses_count', 'listed_count_binary', 'bot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = training_data.bot\n",
    "X = training_data[features].iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "classificators = [\n",
    "    DecisionTreeClassifier(),\n",
    "    MultinomialNB(),\n",
    "    RandomForestClassifier(),\n",
    "    LinearSVC(),\n",
    "    LogisticRegression(),\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    Perceptron()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "Trainig Accuracy: 0.99949\n",
      "Test Accuracy: 0.86310\n",
      "Confusion matrix: \n",
      "[[377  46]\n",
      " [ 69 348]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       423\n",
      "           1       0.88      0.83      0.86       417\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       840\n",
      "   macro avg       0.86      0.86      0.86       840\n",
      "weighted avg       0.86      0.86      0.86       840\n",
      "\n",
      "\n",
      "MultinomialNB\n",
      "Trainig Accuracy: 0.67910\n",
      "Test Accuracy: 0.69762\n",
      "Confusion matrix: \n",
      "[[181 242]\n",
      " [ 12 405]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.43      0.59       423\n",
      "           1       0.63      0.97      0.76       417\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       840\n",
      "   macro avg       0.78      0.70      0.67       840\n",
      "weighted avg       0.78      0.70      0.67       840\n",
      "\n",
      "\n",
      "RandomForestClassifier\n",
      "Trainig Accuracy: 0.99080\n",
      "Test Accuracy: 0.89048\n",
      "Confusion matrix: \n",
      "[[387  36]\n",
      " [ 56 361]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       423\n",
      "           1       0.91      0.87      0.89       417\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       840\n",
      "   macro avg       0.89      0.89      0.89       840\n",
      "weighted avg       0.89      0.89      0.89       840\n",
      "\n",
      "\n",
      "LinearSVC\n",
      "Trainig Accuracy: 0.67859\n",
      "Test Accuracy: 0.69762\n",
      "Confusion matrix: \n",
      "[[200 223]\n",
      " [ 31 386]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.47      0.61       423\n",
      "           1       0.63      0.93      0.75       417\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       840\n",
      "   macro avg       0.75      0.70      0.68       840\n",
      "weighted avg       0.75      0.70      0.68       840\n",
      "\n",
      "\n",
      "LogisticRegression\n",
      "Trainig Accuracy: 0.69494\n",
      "Test Accuracy: 0.70238\n",
      "Confusion matrix: \n",
      "[[195 228]\n",
      " [ 22 395]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.46      0.61       423\n",
      "           1       0.63      0.95      0.76       417\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       840\n",
      "   macro avg       0.77      0.70      0.68       840\n",
      "weighted avg       0.77      0.70      0.68       840\n",
      "\n",
      "\n",
      "GaussianNB\n",
      "Trainig Accuracy: 0.61778\n",
      "Test Accuracy: 0.64643\n",
      "Confusion matrix: \n",
      "[[131 292]\n",
      " [  5 412]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.31      0.47       423\n",
      "           1       0.59      0.99      0.74       417\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       840\n",
      "   macro avg       0.77      0.65      0.60       840\n",
      "weighted avg       0.78      0.65      0.60       840\n",
      "\n",
      "\n",
      "KNeighborsClassifier\n",
      "Trainig Accuracy: 0.86510\n",
      "Test Accuracy: 0.83214\n",
      "Confusion matrix: \n",
      "[[343  80]\n",
      " [ 61 356]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83       423\n",
      "           1       0.82      0.85      0.83       417\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       840\n",
      "   macro avg       0.83      0.83      0.83       840\n",
      "weighted avg       0.83      0.83      0.83       840\n",
      "\n",
      "\n",
      "GradientBoostingClassifier\n",
      "Trainig Accuracy: 0.93357\n",
      "Test Accuracy: 0.89048\n",
      "Confusion matrix: \n",
      "[[384  39]\n",
      " [ 53 364]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       423\n",
      "           1       0.90      0.87      0.89       417\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       840\n",
      "   macro avg       0.89      0.89      0.89       840\n",
      "weighted avg       0.89      0.89      0.89       840\n",
      "\n",
      "\n",
      "Perceptron\n",
      "Trainig Accuracy: 0.67808\n",
      "Test Accuracy: 0.69286\n",
      "Confusion matrix: \n",
      "[[187 236]\n",
      " [ 22 395]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.44      0.59       423\n",
      "           1       0.63      0.95      0.75       417\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       840\n",
      "   macro avg       0.76      0.69      0.67       840\n",
      "weighted avg       0.76      0.69      0.67       840\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in classificators:\n",
    "    print(model.__class__.__name__)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "    model = model.fit(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    print(\"Trainig Accuracy: %.5f\" %accuracy_score(y_train, y_pred_train))\n",
    "    print(\"Test Accuracy: %.5f\" %accuracy_score(y_test, y_pred_test))\n",
    "    print(\"Confusion matrix: \")\n",
    "    print(confusion_matrix(y_test, y_pred_test))\n",
    "    print(\"Classification report: \")\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
